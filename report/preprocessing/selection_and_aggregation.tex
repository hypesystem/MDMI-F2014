\subsection{Selection and Aggregation}
\label{sec:preprocessing_selection}
A number of attributes of the songs were not appropriate to use for similarity analysis. Consider the artist name attribute for example. Two songs by the same artist are obviously similar in that attribute, but might be completely different in their harmonic, dynamic and spectral content. As a consequence, attributes such as artist name, song name, release year etc. were ignored for the data mining process. The attributes selected for use in later data mining processes were segments and sections data, in addition to structural and harmonic metadata attributes such as key-signature, tempo, and time signature.
\\\\
In order to compare the segments and sections data of two songs to determine their similarity, it is necessary to process the lists of data to produce a comparable representation. Segments data, for example, is not directly comparable from one song to another, since it represents a piece of the audio that is uniform in harmonic, dynamic and spectral content. This means that there is no straightforward way of determining which segments of two songs should be used for comparison. Moreover, whether two segments of any two songs are similar or not, is not indicative of whether the songs are similar as a whole.
\\\\
The approach we adopted was to aggregate the segments and sections data, as suggested by a research article testing the effectiveness of different classification algorithms on the LABROSA million song dataset \citep{schindler12}. In this scheme, every attribute of the segments are aggregated to 8 statistical moments: mean, median, max, min, value range, skewness, kurtosis and variance. The vector attributes, pitch and timbre, have each of their dimensions aggregated in the same manner: each of the dimensions are aggregated into these 8 statistical moments. These aggregates can then be used to used to compare the songs.

% section preprocessing (end)